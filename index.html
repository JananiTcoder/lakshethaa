<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>AR Image Replacement</title>
<script async src="https://docs.opencv.org/4.x/opencv.js"></script>
<style>
  body { margin:0; background:black; overflow:hidden; }
  canvas { width:100vw; height:100vh; object-fit:cover; display:block; }
  #videoSource, #videoCanvas { display:none; }
</style>
</head>
<body>

<!-- Hidden video and canvas for processing -->
<video id="videoSource" src="output.mp4" autoplay loop muted playsinline></video>
<canvas id="videoCanvas"></canvas>

<!-- Camera and output -->
<video id="camera" autoplay playsinline muted></video>
<canvas id="canvas"></canvas>
<img id="referenceImg" src="reference.jpg" style="display:none;">

<script>
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
const camera = document.getElementById('camera');
const videoSource = document.getElementById('videoSource');
const videoCanvas = document.getElementById('videoCanvas');
const videoCtx = videoCanvas.getContext('2d');
const refImg = document.getElementById('referenceImg');

// START BACK CAMERA
async function startCamera() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: { exact: "environment" } },
            audio: false
        });
        camera.srcObject = stream;
    } catch (e) {
        console.warn("Back camera failed, falling back to default", e);
        const stream = await navigator.mediaDevices.getUserMedia({ video:true, audio:false });
        camera.srcObject = stream;
    }
}
startCamera();

cv['onRuntimeInitialized'] = () => {
    const refColor = cv.imread(refImg);
    const refGray = new cv.Mat();
    cv.cvtColor(refColor, refGray, cv.COLOR_BGR2GRAY);

    const orb = new cv.ORB();
    const kpRef = new cv.KeyPointVector();
    const descRef = new cv.Mat();
    orb.detectAndCompute(refGray, new cv.Mat(), kpRef, descRef);
    const bf = new cv.BFMatcher(cv.NORM_HAMMING);

    function process() {
        if(camera.readyState !== 4) { requestAnimationFrame(process); return; }

        // Draw camera
        canvas.width = camera.videoWidth;
        canvas.height = camera.videoHeight;
        ctx.drawImage(camera,0,0,canvas.width,canvas.height);

        const frame = cv.imread(canvas);
        const grayFrame = new cv.Mat();
        cv.cvtColor(frame, grayFrame, cv.COLOR_BGR2GRAY);

        const kpFrame = new cv.KeyPointVector();
        const descFrame = new cv.Mat();
        orb.detectAndCompute(grayFrame, new cv.Mat(), kpFrame, descFrame);

        if(!descFrame.empty()) {
            const matches = new cv.DMatchVector();
            bf.match(descRef, descFrame, matches);

            let goodMatches = [];
            for(let i=0;i<matches.size();i++){
                if(matches.get(i).distance < 50) goodMatches.push(matches.get(i));
            }

            if(goodMatches.length >= 10) {
                // Homography points
                let srcPts = [], dstPts = [];
                for(let i=0;i<goodMatches.length;i++){
                    srcPts.push(kpRef.get(goodMatches[i].queryIdx).pt.x);
                    srcPts.push(kpRef.get(goodMatches[i].queryIdx).pt.y);
                    dstPts.push(kpFrame.get(goodMatches[i].trainIdx).pt.x);
                    dstPts.push(kpFrame.get(goodMatches[i].trainIdx).pt.y);
                }

                const srcMat = cv.matFromArray(goodMatches.length,1,cv.CV_32FC2,srcPts);
                const dstMat = cv.matFromArray(goodMatches.length,1,cv.CV_32FC2,dstPts);
                const mask = new cv.Mat();
                const H = cv.findHomography(srcMat, dstMat, cv.RANSAC,5,mask);

                if(!H.empty()) {
                    // Draw video frame to hidden canvas
                    videoCanvas.width = videoSource.videoWidth;
                    videoCanvas.height = videoSource.videoHeight;
                    videoCtx.drawImage(videoSource,0,0,videoCanvas.width,videoCanvas.height);
                    const vidFrame = cv.imread(videoCanvas);

                    const warped = new cv.Mat();
                    const dsize = new cv.Size(frame.cols, frame.rows);
                    cv.warpPerspective(vidFrame, warped, H, dsize);

                    // Overlay
                    cv.addWeighted(warped,1.0,frame,0,0,frame);
                    cv.imshow(canvas, frame);

                    vidFrame.delete();
                    warped.delete();
                    H.delete();
                    srcMat.delete();
                    dstMat.delete();
                    mask.delete();
                }
            }
            matches.delete();
        }

        frame.delete();
        grayFrame.delete();
        kpFrame.delete();
        descFrame.delete();

        requestAnimationFrame(process);
    }

    process();
};
</script>
</body>
</html>
