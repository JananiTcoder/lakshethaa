<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Camera Image Detection (ORB)</title>

  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>

  <style>
    body {
      margin: 0;
      background: black;
      overflow: hidden;
    }

    #cameraView {
      width: 100vw;
      height: 100vh;
      object-fit: cover;
    }

    #overlay {
      position: absolute;
      top: 30%;
      left: 50%;
      transform: translateX(-50%);
      width: 300px;
      height: 200px;
    }

    #resultVideo {
      display: none;
      width: 100%;
      height: 100%;
    }

    #camera, #canvas, #referenceImg {
      display: none;
    }
  </style>
</head>
<body>

<!-- Visible camera -->
<video id="cameraView" autoplay playsinline muted></video>

<div id="overlay">
  <video id="resultVideo" src="output.mp4" controls></video>
</div>

<!-- Hidden processing elements -->
<video id="camera" autoplay playsinline></video>
<canvas id="canvas"></canvas>
<img id="referenceImg" src="reference.jpg">

<script>
const camera = document.getElementById("camera");
const cameraView = document.getElementById("cameraView");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const refImg = document.getElementById("referenceImg");
const resultVideo = document.getElementById("resultVideo");

/* ---------- FORCE BACK CAMERA ---------- */
async function startBackCamera() {
  try {
    // Preferred: strict rear camera
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: { exact: "environment" } },
      audio: false
    });
    camera.srcObject = stream;
    cameraView.srcObject = stream;
  } catch (err) {
    // Fallback: rear camera if exact not supported
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: "environment" },
      audio: false
    });
    camera.srcObject = stream;
    cameraView.srcObject = stream;
  }
}

startBackCamera();

/* ---------- OPENCV LOGIC ---------- */
refImg.onload = () => {
  cv.onRuntimeInitialized = () => {
    console.log("OpenCV ready (ORB)");

    let refColor = cv.imread(refImg);
    let refGray = new cv.Mat();
    cv.cvtColor(refColor, refGray, cv.COLOR_BGR2GRAY);

    let orb = new cv.ORB();
    let refKeypoints = new cv.KeyPointVector();
    let refDescriptors = new cv.Mat();

    orb.detectAndCompute(refGray, new cv.Mat(), refKeypoints, refDescriptors);

    function detect() {
      if (camera.readyState !== 4) {
        requestAnimationFrame(detect);
        return;
      }

      const scale = 0.5;
      canvas.width = camera.videoWidth * scale;
      canvas.height = camera.videoHeight * scale;
      ctx.drawImage(camera, 0, 0, canvas.width, canvas.height);

      let frameColor = cv.imread(canvas);
      let frameGray = new cv.Mat();
      cv.cvtColor(frameColor, frameGray, cv.COLOR_BGR2GRAY);

      let frameKeypoints = new cv.KeyPointVector();
      let frameDescriptors = new cv.Mat();

      orb.detectAndCompute(frameGray, new cv.Mat(), frameKeypoints, frameDescriptors);

      if (!frameDescriptors.empty()) {
        let bf = new cv.BFMatcher(cv.NORM_HAMMING, true);
        let matches = new cv.DMatchVector();

        bf.match(refDescriptors, frameDescriptors, matches);

        let goodMatches = 0;
        for (let i = 0; i < matches.size(); i++) {
          if (matches.get(i).distance < 50) goodMatches++;
        }

        if (goodMatches > 15) {
          resultVideo.style.display = "block";
          resultVideo.muted = false;
          resultVideo.play();
          return;
        }

        matches.delete();
        bf.delete();
      }

      frameColor.delete();
      frameGray.delete();
      frameKeypoints.delete();
      frameDescriptors.delete();

      requestAnimationFrame(detect);
    }

    detect();
  };
};
</script>

</body>
</html>
